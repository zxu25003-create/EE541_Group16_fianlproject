{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c912ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:38:15.241156Z",
     "iopub.status.busy": "2025-12-05T03:38:15.240291Z",
     "iopub.status.idle": "2025-12-05T03:38:19.017787Z",
     "shell.execute_reply": "2025-12-05T03:38:19.016992Z",
     "shell.execute_reply.started": "2025-12-05T03:38:15.241129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/kaggle/input/project-541/project')\n",
    "\n",
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from augment import WaveformAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfe725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:38:19.019489Z",
     "iopub.status.busy": "2025-12-05T03:38:19.019087Z",
     "iopub.status.idle": "2025-12-05T03:38:19.083209Z",
     "shell.execute_reply": "2025-12-05T03:38:19.082580Z",
     "shell.execute_reply.started": "2025-12-05T03:38:19.019468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# configurations \n",
    "\n",
    "DATA_DIR = \"./data/UrbanSound8K\" # dataset path\n",
    "MODEL_DIR = \"./model/model-d\" # store trained model and figure (path)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE = 22050 # sample rate\n",
    "CLIP_DURATION = 4.0 # length of clip\n",
    "N_CLASSES = 10\n",
    "\n",
    "BATCH_SIZE = 16 # batch size\n",
    "NUM_EPOCHS = 20 # epoch\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc0cce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:38:19.084251Z",
     "iopub.status.busy": "2025-12-05T03:38:19.083985Z",
     "iopub.status.idle": "2025-12-05T03:38:19.100719Z",
     "shell.execute_reply": "2025-12-05T03:38:19.099994Z",
     "shell.execute_reply.started": "2025-12-05T03:38:19.084221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset construct\n",
    "\n",
    "class UrbanSound8KWaveformDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        folds: List[int],\n",
    "        sample_rate: int = SAMPLE_RATE,\n",
    "        duration: float = CLIP_DURATION,\n",
    "        waveform_augment: WaveformAugment = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.folds = folds if isinstance(folds, list) else [folds]\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.n_samples = int(sample_rate * duration)\n",
    "        self.waveform_augment = waveform_augment\n",
    "\n",
    "        # 读取 metadata\n",
    "        meta_path = os.path.join(data_dir, \"metadata\", \"UrbanSound8K.csv\")\n",
    "        self.df = pd.read_csv(meta_path)\n",
    "        self.df = self.df[self.df[\"fold\"].isin(self.folds)].reset_index(drop=True)\n",
    "        self.labels = self.df[\"classID\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _load_waveform(self, index: int) -> np.ndarray:\n",
    "        row = self.df.iloc[index]\n",
    "        fold = row[\"fold\"]\n",
    "        filename = row[\"slice_file_name\"]\n",
    "        file_path = os.path.join(self.data_dir, \"audio\", f\"fold{fold}\", filename)\n",
    "\n",
    "        # resample\n",
    "        wav, sr = librosa.load(file_path, sr=self.sample_rate, mono=True)\n",
    "\n",
    "        # pad / truncate to 4 seconds\n",
    "        if len(wav) < self.n_samples:\n",
    "            pad_width = self.n_samples - len(wav)\n",
    "            wav = np.pad(wav, (0, pad_width), mode=\"constant\")\n",
    "        elif len(wav) > self.n_samples:\n",
    "            wav = wav[: self.n_samples]\n",
    "\n",
    "        # normalization\n",
    "        if np.std(wav) > 1e-6:\n",
    "            wav = (wav - np.mean(wav)) / np.std(wav)\n",
    "\n",
    "        return wav.astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        label = int(self.labels[index])\n",
    "        wav_np = self._load_waveform(index)\n",
    "        wav = torch.from_numpy(wav_np).unsqueeze(0) # [1, T] (channels, samples)\n",
    "\n",
    "        # data augmentation (for train set)\n",
    "        if self.waveform_augment is not None:\n",
    "            wav = self.waveform_augment(wav)\n",
    "\n",
    "        return wav, torch.tensor(label, dtype=torch.long) # return waveform [1, T] and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "303e60ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:38:19.102470Z",
     "iopub.status.busy": "2025-12-05T03:38:19.102185Z",
     "iopub.status.idle": "2025-12-05T03:38:19.118851Z",
     "shell.execute_reply": "2025-12-05T03:38:19.118098Z",
     "shell.execute_reply.started": "2025-12-05T03:38:19.102450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# VGG-13 1D model\n",
    "\n",
    "class VGG13_1D(nn.Module):\n",
    "    \"\"\"\n",
    "    [64,64,'M', 128,128,'M', 256,256,'M', 512,512,'M', 512,512,'M']\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = N_CLASSES, in_channels: int = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        cfg = [64, 64, 'M',\n",
    "               128, 128, 'M',\n",
    "               256, 256, 'M',\n",
    "               512, 512, 'M',\n",
    "               512, 512, 'M']\n",
    "\n",
    "        self.features = self.make_layers(cfg, in_channels)\n",
    "        # Global Average Pooling and FC\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1) # used for match the shape\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layers(self, cfg, in_channels): # construct layer\n",
    "        layers = []\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool1d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [\n",
    "                    nn.Conv1d(in_channels, v, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm1d(v),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                ]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 1, T]\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.squeeze(-1) # [B, 512]\n",
    "        x = self.classifier(x) # [B, num_classes]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd770c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:38:19.119993Z",
     "iopub.status.busy": "2025-12-05T03:38:19.119732Z",
     "iopub.status.idle": "2025-12-05T03:38:19.143672Z",
     "shell.execute_reply": "2025-12-05T03:38:19.142832Z",
     "shell.execute_reply.started": "2025-12-05T03:38:19.119971Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Functions for train, validate and plot\n",
    "\n",
    "def set_seed(seed: int = 38):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device: torch.device): # train one epoch\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # zero gradient\n",
    "        logits = model(x) # forward\n",
    "        loss = criterion(logits, y) # loss\n",
    "        loss.backward() # backward\n",
    "        optimizer.step() # update\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "@torch.no_grad() # evaluate\n",
    "def evaluate(model, loader, criterion, device: torch.device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def plot_learning_curve(history, fold_id: int, save_dir: str = MODEL_DIR): # plot\n",
    "    \"\"\"\n",
    "    history: dict with keys 'train_loss', 'val_loss', 'train_acc', 'val_acc'\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"d - Fold {fold_id} - Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"d - Fold {fold_id} - Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, f\"vgg13_d_fold{fold_id}_curve.png\")\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved learning curve to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac36ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T03:38:19.144754Z",
     "iopub.status.busy": "2025-12-05T03:38:19.144505Z",
     "iopub.status.idle": "2025-12-05T10:05:35.007230Z",
     "shell.execute_reply": "2025-12-05T10:05:35.005758Z",
     "shell.execute_reply.started": "2025-12-05T03:38:19.144734Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Fold 1 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Val fold: 10\n",
      "Test fold: 1\n",
      "\n",
      "[Fold 1] Epoch 1/20\n",
      "Train Loss: 1.6581, Train Acc: 0.3989\n",
      "Val   Loss: 1.7919, Val   Acc: 0.4134\n",
      "\n",
      "[Fold 1] Epoch 2/20\n",
      "Train Loss: 1.4953, Train Acc: 0.4583\n",
      "Val   Loss: 1.6322, Val   Acc: 0.4779\n",
      "\n",
      "[Fold 1] Epoch 3/20\n",
      "Train Loss: 1.4267, Train Acc: 0.4910\n",
      "Val   Loss: 1.6746, Val   Acc: 0.4134\n",
      "\n",
      "[Fold 1] Epoch 4/20\n",
      "Train Loss: 1.3783, Train Acc: 0.5078\n",
      "Val   Loss: 1.6329, Val   Acc: 0.4385\n",
      "\n",
      "[Fold 1] Epoch 5/20\n",
      "Train Loss: 1.3261, Train Acc: 0.5275\n",
      "Val   Loss: 1.6567, Val   Acc: 0.4074\n",
      "\n",
      "[Fold 1] Epoch 6/20\n",
      "Train Loss: 1.2952, Train Acc: 0.5422\n",
      "Val   Loss: 1.6039, Val   Acc: 0.4659\n",
      "\n",
      "[Fold 1] Epoch 7/20\n",
      "Train Loss: 1.2655, Train Acc: 0.5538\n",
      "Val   Loss: 1.7320, Val   Acc: 0.4504\n",
      "\n",
      "[Fold 1] Epoch 8/20\n",
      "Train Loss: 1.2342, Train Acc: 0.5741\n",
      "Val   Loss: 1.5681, Val   Acc: 0.5090\n",
      "\n",
      "[Fold 1] Epoch 9/20\n",
      "Train Loss: 1.2153, Train Acc: 0.5807\n",
      "Val   Loss: 1.5297, Val   Acc: 0.5818\n",
      "\n",
      "[Fold 1] Epoch 10/20\n",
      "Train Loss: 1.1901, Train Acc: 0.5810\n",
      "Val   Loss: 1.5826, Val   Acc: 0.4385\n",
      "\n",
      "[Fold 1] Epoch 11/20\n",
      "Train Loss: 1.1729, Train Acc: 0.5938\n",
      "Val   Loss: 1.6479, Val   Acc: 0.4791\n",
      "\n",
      "[Fold 1] Epoch 12/20\n",
      "Train Loss: 1.1534, Train Acc: 0.6050\n",
      "Val   Loss: 1.6923, Val   Acc: 0.4540\n",
      "\n",
      "[Fold 1] Epoch 13/20\n",
      "Train Loss: 1.1368, Train Acc: 0.6122\n",
      "Val   Loss: 1.6143, Val   Acc: 0.5114\n",
      "\n",
      "[Fold 1] Epoch 14/20\n",
      "Train Loss: 1.1175, Train Acc: 0.6131\n",
      "Val   Loss: 1.7551, Val   Acc: 0.4349\n",
      "\n",
      "[Fold 1] Epoch 15/20\n",
      "Train Loss: 1.0952, Train Acc: 0.6265\n",
      "Val   Loss: 1.4691, Val   Acc: 0.5352\n",
      "\n",
      "[Fold 1] Epoch 16/20\n",
      "Train Loss: 1.0830, Train Acc: 0.6341\n",
      "Val   Loss: 1.4895, Val   Acc: 0.5161\n",
      "\n",
      "[Fold 1] Epoch 17/20\n",
      "Train Loss: 1.0648, Train Acc: 0.6397\n",
      "Val   Loss: 1.5955, Val   Acc: 0.4839\n",
      "\n",
      "[Fold 1] Epoch 18/20\n",
      "Train Loss: 1.0515, Train Acc: 0.6437\n",
      "Val   Loss: 1.4697, Val   Acc: 0.5173\n",
      "\n",
      "[Fold 1] Epoch 19/20\n",
      "Train Loss: 1.0418, Train Acc: 0.6440\n",
      "Val   Loss: 2.0156, Val   Acc: 0.4313\n",
      "\n",
      "[Fold 1] Epoch 20/20\n",
      "Train Loss: 1.0308, Train Acc: 0.6470\n",
      "Val   Loss: 1.6798, Val   Acc: 0.4707\n",
      "Saved learning curve to: /kaggle/working/model-d/vgg13_d_fold1_curve.png\n",
      "[Fold 1] Test Loss: 2.1401, Test Acc: 0.4456\n",
      "Saved model for fold 1 to: /kaggle/working/model-d/vgg13_d_fold1.pth\n",
      "================================================================================\n",
      "Fold 2 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 3, 4, 5, 6, 7, 8, 9]\n",
      "Val fold: 10\n",
      "Test fold: 2\n",
      "\n",
      "[Fold 2] Epoch 1/20\n",
      "Train Loss: 1.6407, Train Acc: 0.4100\n",
      "Val   Loss: 1.7323, Val   Acc: 0.3978\n",
      "\n",
      "[Fold 2] Epoch 2/20\n",
      "Train Loss: 1.4832, Train Acc: 0.4701\n",
      "Val   Loss: 1.6428, Val   Acc: 0.4516\n",
      "\n",
      "[Fold 2] Epoch 3/20\n",
      "Train Loss: 1.4168, Train Acc: 0.4942\n",
      "Val   Loss: 1.6413, Val   Acc: 0.4002\n",
      "\n",
      "[Fold 2] Epoch 4/20\n",
      "Train Loss: 1.3608, Train Acc: 0.5161\n",
      "Val   Loss: 1.7052, Val   Acc: 0.4946\n",
      "\n",
      "[Fold 2] Epoch 5/20\n",
      "Train Loss: 1.3175, Train Acc: 0.5335\n",
      "Val   Loss: 1.4990, Val   Acc: 0.5197\n",
      "\n",
      "[Fold 2] Epoch 6/20\n",
      "Train Loss: 1.2869, Train Acc: 0.5524\n",
      "Val   Loss: 1.6548, Val   Acc: 0.5054\n",
      "\n",
      "[Fold 2] Epoch 7/20\n",
      "Train Loss: 1.2685, Train Acc: 0.5477\n",
      "Val   Loss: 1.5136, Val   Acc: 0.5114\n",
      "\n",
      "[Fold 2] Epoch 8/20\n",
      "Train Loss: 1.2362, Train Acc: 0.5719\n",
      "Val   Loss: 1.8227, Val   Acc: 0.4313\n",
      "\n",
      "[Fold 2] Epoch 9/20\n",
      "Train Loss: 1.2022, Train Acc: 0.5811\n",
      "Val   Loss: 1.5736, Val   Acc: 0.5281\n",
      "\n",
      "[Fold 2] Epoch 10/20\n",
      "Train Loss: 1.1934, Train Acc: 0.5866\n",
      "Val   Loss: 1.6846, Val   Acc: 0.4659\n",
      "\n",
      "[Fold 2] Epoch 11/20\n",
      "Train Loss: 1.1859, Train Acc: 0.5926\n",
      "Val   Loss: 1.5208, Val   Acc: 0.4994\n",
      "\n",
      "[Fold 2] Epoch 12/20\n",
      "Train Loss: 1.1649, Train Acc: 0.6013\n",
      "Val   Loss: 1.9598, Val   Acc: 0.3978\n",
      "\n",
      "[Fold 2] Epoch 13/20\n",
      "Train Loss: 1.1456, Train Acc: 0.6027\n",
      "Val   Loss: 1.4074, Val   Acc: 0.5317\n",
      "\n",
      "[Fold 2] Epoch 14/20\n",
      "Train Loss: 1.1193, Train Acc: 0.6125\n",
      "Val   Loss: 1.4810, Val   Acc: 0.4851\n",
      "\n",
      "[Fold 2] Epoch 15/20\n",
      "Train Loss: 1.1079, Train Acc: 0.6164\n",
      "Val   Loss: 1.5211, Val   Acc: 0.4779\n",
      "\n",
      "[Fold 2] Epoch 16/20\n",
      "Train Loss: 1.1001, Train Acc: 0.6204\n",
      "Val   Loss: 1.6868, Val   Acc: 0.4648\n",
      "\n",
      "[Fold 2] Epoch 17/20\n",
      "Train Loss: 1.0774, Train Acc: 0.6254\n",
      "Val   Loss: 1.4942, Val   Acc: 0.5137\n",
      "\n",
      "[Fold 2] Epoch 18/20\n",
      "Train Loss: 1.0607, Train Acc: 0.6352\n",
      "Val   Loss: 1.6966, Val   Acc: 0.4659\n",
      "\n",
      "[Fold 2] Epoch 19/20\n",
      "Train Loss: 1.0500, Train Acc: 0.6398\n",
      "Val   Loss: 1.6138, Val   Acc: 0.4552\n",
      "\n",
      "[Fold 2] Epoch 20/20\n",
      "Train Loss: 1.0572, Train Acc: 0.6382\n",
      "Val   Loss: 1.7598, Val   Acc: 0.4504\n",
      "Saved learning curve to: /kaggle/working/model-d/vgg13_d_fold2_curve.png\n",
      "[Fold 2] Test Loss: 1.5701, Test Acc: 0.4718\n",
      "Saved model for fold 2 to: /kaggle/working/model-d/vgg13_d_fold2.pth\n",
      "================================================================================\n",
      "Fold 3 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 4, 5, 6, 7, 8, 9]\n",
      "Val fold: 10\n",
      "Test fold: 3\n",
      "\n",
      "[Fold 3] Epoch 1/20\n",
      "Train Loss: 1.6695, Train Acc: 0.4059\n",
      "Val   Loss: 1.5695, Val   Acc: 0.4564\n",
      "\n",
      "[Fold 3] Epoch 2/20\n",
      "Train Loss: 1.4837, Train Acc: 0.4663\n",
      "Val   Loss: 1.7081, Val   Acc: 0.3823\n",
      "\n",
      "[Fold 3] Epoch 3/20\n",
      "Train Loss: 1.4098, Train Acc: 0.4984\n",
      "Val   Loss: 1.7148, Val   Acc: 0.4098\n",
      "\n",
      "[Fold 3] Epoch 4/20\n",
      "Train Loss: 1.3665, Train Acc: 0.5154\n",
      "Val   Loss: 1.6081, Val   Acc: 0.5305\n",
      "\n",
      "[Fold 3] Epoch 5/20\n",
      "Train Loss: 1.3259, Train Acc: 0.5319\n",
      "Val   Loss: 1.5004, Val   Acc: 0.4839\n",
      "\n",
      "[Fold 3] Epoch 6/20\n",
      "Train Loss: 1.2872, Train Acc: 0.5449\n",
      "Val   Loss: 1.4380, Val   Acc: 0.5006\n",
      "\n",
      "[Fold 3] Epoch 7/20\n",
      "Train Loss: 1.2501, Train Acc: 0.5643\n",
      "Val   Loss: 1.6407, Val   Acc: 0.4576\n",
      "\n",
      "[Fold 3] Epoch 8/20\n",
      "Train Loss: 1.2347, Train Acc: 0.5664\n",
      "Val   Loss: 1.5069, Val   Acc: 0.4898\n",
      "\n",
      "[Fold 3] Epoch 9/20\n",
      "Train Loss: 1.2099, Train Acc: 0.5743\n",
      "Val   Loss: 1.4150, Val   Acc: 0.5137\n",
      "\n",
      "[Fold 3] Epoch 10/20\n",
      "Train Loss: 1.1890, Train Acc: 0.5872\n",
      "Val   Loss: 1.5506, Val   Acc: 0.4922\n",
      "\n",
      "[Fold 3] Epoch 11/20\n",
      "Train Loss: 1.1638, Train Acc: 0.5990\n",
      "Val   Loss: 1.4495, Val   Acc: 0.5030\n",
      "\n",
      "[Fold 3] Epoch 12/20\n",
      "Train Loss: 1.1591, Train Acc: 0.6010\n",
      "Val   Loss: 1.4129, Val   Acc: 0.5424\n",
      "\n",
      "[Fold 3] Epoch 13/20\n",
      "Train Loss: 1.1242, Train Acc: 0.6109\n",
      "Val   Loss: 1.4796, Val   Acc: 0.4886\n",
      "\n",
      "[Fold 3] Epoch 14/20\n",
      "Train Loss: 1.1190, Train Acc: 0.6129\n",
      "Val   Loss: 1.5969, Val   Acc: 0.4886\n",
      "\n",
      "[Fold 3] Epoch 15/20\n",
      "Train Loss: 1.1090, Train Acc: 0.6181\n",
      "Val   Loss: 1.7706, Val   Acc: 0.4409\n",
      "\n",
      "[Fold 3] Epoch 16/20\n",
      "Train Loss: 1.0918, Train Acc: 0.6238\n",
      "Val   Loss: 1.6175, Val   Acc: 0.4898\n",
      "\n",
      "[Fold 3] Epoch 17/20\n",
      "Train Loss: 1.0775, Train Acc: 0.6357\n",
      "Val   Loss: 1.5704, Val   Acc: 0.5472\n",
      "\n",
      "[Fold 3] Epoch 18/20\n",
      "Train Loss: 1.0564, Train Acc: 0.6369\n",
      "Val   Loss: 1.6628, Val   Acc: 0.5114\n",
      "\n",
      "[Fold 3] Epoch 19/20\n",
      "Train Loss: 1.0649, Train Acc: 0.6343\n",
      "Val   Loss: 1.5705, Val   Acc: 0.4648\n",
      "\n",
      "[Fold 3] Epoch 20/20\n",
      "Train Loss: 1.0385, Train Acc: 0.6395\n",
      "Val   Loss: 1.6085, Val   Acc: 0.4743\n",
      "Saved learning curve to: /kaggle/working/model-d/vgg13_d_fold3_curve.png\n",
      "[Fold 3] Test Loss: 1.9654, Test Acc: 0.5016\n",
      "Saved model for fold 3 to: /kaggle/working/model-d/vgg13_d_fold3.pth\n",
      "================================================================================\n",
      "Fold 4 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 5, 6, 7, 8, 9]\n",
      "Val fold: 10\n",
      "Test fold: 4\n",
      "\n",
      "[Fold 4] Epoch 1/20\n",
      "Train Loss: 1.6652, Train Acc: 0.3917\n",
      "Val   Loss: 1.7191, Val   Acc: 0.4205\n",
      "\n",
      "[Fold 4] Epoch 2/20\n",
      "Train Loss: 1.4967, Train Acc: 0.4565\n",
      "Val   Loss: 1.9488, Val   Acc: 0.3787\n",
      "\n",
      "[Fold 4] Epoch 3/20\n",
      "Train Loss: 1.4190, Train Acc: 0.4831\n",
      "Val   Loss: 1.7213, Val   Acc: 0.4265\n",
      "\n",
      "[Fold 4] Epoch 4/20\n",
      "Train Loss: 1.3656, Train Acc: 0.5128\n",
      "Val   Loss: 1.5418, Val   Acc: 0.4504\n",
      "\n",
      "[Fold 4] Epoch 5/20\n",
      "Train Loss: 1.3232, Train Acc: 0.5248\n",
      "Val   Loss: 1.5877, Val   Acc: 0.4432\n",
      "\n",
      "[Fold 4] Epoch 6/20\n",
      "Train Loss: 1.3002, Train Acc: 0.5370\n",
      "Val   Loss: 1.4183, Val   Acc: 0.5137\n",
      "\n",
      "[Fold 4] Epoch 7/20\n",
      "Train Loss: 1.2624, Train Acc: 0.5557\n",
      "Val   Loss: 1.9062, Val   Acc: 0.4098\n",
      "\n",
      "[Fold 4] Epoch 8/20\n",
      "Train Loss: 1.2250, Train Acc: 0.5670\n",
      "Val   Loss: 1.5034, Val   Acc: 0.4886\n",
      "\n",
      "[Fold 4] Epoch 9/20\n",
      "Train Loss: 1.2084, Train Acc: 0.5770\n",
      "Val   Loss: 1.4999, Val   Acc: 0.4934\n",
      "\n",
      "[Fold 4] Epoch 10/20\n",
      "Train Loss: 1.1911, Train Acc: 0.5800\n",
      "Val   Loss: 1.5958, Val   Acc: 0.4695\n",
      "\n",
      "[Fold 4] Epoch 11/20\n",
      "Train Loss: 1.1687, Train Acc: 0.5875\n",
      "Val   Loss: 1.5617, Val   Acc: 0.4659\n",
      "\n",
      "[Fold 4] Epoch 12/20\n",
      "Train Loss: 1.1459, Train Acc: 0.5997\n",
      "Val   Loss: 1.4599, Val   Acc: 0.5233\n",
      "\n",
      "[Fold 4] Epoch 13/20\n",
      "Train Loss: 1.1223, Train Acc: 0.6075\n",
      "Val   Loss: 1.5630, Val   Acc: 0.4695\n",
      "\n",
      "[Fold 4] Epoch 14/20\n",
      "Train Loss: 1.1093, Train Acc: 0.6232\n",
      "Val   Loss: 1.6914, Val   Acc: 0.4898\n",
      "\n",
      "[Fold 4] Epoch 15/20\n",
      "Train Loss: 1.0908, Train Acc: 0.6213\n",
      "Val   Loss: 1.6903, Val   Acc: 0.4636\n",
      "\n",
      "[Fold 4] Epoch 16/20\n",
      "Train Loss: 1.0831, Train Acc: 0.6239\n",
      "Val   Loss: 1.6092, Val   Acc: 0.4480\n",
      "\n",
      "[Fold 4] Epoch 17/20\n",
      "Train Loss: 1.0619, Train Acc: 0.6297\n",
      "Val   Loss: 1.5643, Val   Acc: 0.4791\n",
      "\n",
      "[Fold 4] Epoch 18/20\n",
      "Train Loss: 1.0576, Train Acc: 0.6261\n",
      "Val   Loss: 1.5357, Val   Acc: 0.4863\n",
      "\n",
      "[Fold 4] Epoch 19/20\n",
      "Train Loss: 1.0343, Train Acc: 0.6453\n",
      "Val   Loss: 1.7121, Val   Acc: 0.4492\n",
      "\n",
      "[Fold 4] Epoch 20/20\n",
      "Train Loss: 1.0347, Train Acc: 0.6434\n",
      "Val   Loss: 1.3521, Val   Acc: 0.5699\n",
      "Saved learning curve to: /kaggle/working/model-d/vgg13_d_fold4_curve.png\n",
      "[Fold 4] Test Loss: 1.8190, Test Acc: 0.4970\n",
      "Saved model for fold 4 to: /kaggle/working/model-d/vgg13_d_fold4.pth\n",
      "================================================================================\n",
      "Fold 5 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 4, 6, 7, 8, 9]\n",
      "Val fold: 10\n",
      "Test fold: 5\n",
      "\n",
      "[Fold 5] Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/3389185211.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n[Fold {test_fold}] Epoch {epoch}/{NUM_EPOCHS}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_47/784239637.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 10-fold Cross-Validation train\n",
    "\n",
    "set_seed(38)\n",
    "\n",
    "all_folds = list(range(1, 11))\n",
    "\n",
    "for test_fold in all_folds:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Fold {test_fold} as TEST fold\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # current fold as test set, remaining 9 folds as train set and val set\n",
    "    trainval_folds = [f for f in all_folds if f != test_fold]\n",
    "\n",
    "    # last fold of remaining 9 set as val set，remaining 8 folds as train set\n",
    "    val_fold = trainval_folds[-1]\n",
    "    train_folds = trainval_folds[:-1]\n",
    "\n",
    "    print(f\"Train folds: {train_folds}\")\n",
    "    print(f\"Val fold: {val_fold}\")\n",
    "    print(f\"Test fold: {test_fold}\")\n",
    "\n",
    "    # augmentation\n",
    "    wave_aug = WaveformAugment(sample_rate=SAMPLE_RATE)\n",
    "\n",
    "    train_dataset = UrbanSound8KWaveformDataset( # train set\n",
    "        data_dir=DATA_DIR,\n",
    "        folds=train_folds,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        duration=CLIP_DURATION,\n",
    "        waveform_augment=wave_aug # do augmentation\n",
    "    )\n",
    "\n",
    "    val_dataset = UrbanSound8KWaveformDataset( # val set\n",
    "        data_dir=DATA_DIR,\n",
    "        folds=[val_fold],\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        duration=CLIP_DURATION,\n",
    "        waveform_augment=None # don't do augmentation\n",
    "    )\n",
    "\n",
    "    test_dataset = UrbanSound8KWaveformDataset( # test set\n",
    "        data_dir=DATA_DIR,\n",
    "        folds=[test_fold],\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        duration=CLIP_DURATION,\n",
    "        waveform_augment=None # don't do augmentation\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "    # creat model, loss and optimizer\n",
    "    model = VGG13_1D(num_classes=N_CLASSES, in_channels=1).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        print(f\"\\n[Fold {test_fold}] Epoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, DEVICE)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f}, Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # early stop to store the best model (on val set)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # plot learning curve\n",
    "    plot_learning_curve(history, fold_id=test_fold, save_dir=MODEL_DIR)\n",
    "\n",
    "    # load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # test on test set after finishing training\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, DEVICE)\n",
    "    print(f\"[Fold {test_fold}] Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    # store the model\n",
    "    model_path = os.path.join(MODEL_DIR, f\"vgg13_d_fold{test_fold}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model for fold {test_fold} to: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8921116,
     "sourceId": 14000295,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
