{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b7837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:32.632739Z",
     "iopub.status.busy": "2025-12-05T05:22:32.632452Z",
     "iopub.status.idle": "2025-12-05T05:22:39.950556Z",
     "shell.execute_reply": "2025-12-05T05:22:39.949928Z",
     "shell.execute_reply.started": "2025-12-05T05:22:32.632716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/kaggle/input/project-541/project')\n",
    "\n",
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "from augment import WaveformAugment\n",
    "# from specAugment import SpecAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b292cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:39.952646Z",
     "iopub.status.busy": "2025-12-05T05:22:39.951589Z",
     "iopub.status.idle": "2025-12-05T05:22:40.020303Z",
     "shell.execute_reply": "2025-12-05T05:22:40.019533Z",
     "shell.execute_reply.started": "2025-12-05T05:22:39.952619Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# configurations\n",
    "\n",
    "DATA_DIR = \"./data/UrbanSound8K\" # dataset path\n",
    "MODEL_DIR = \"./model/model-e\" # store trained model and figure (path)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE = 22050 # sample rate\n",
    "CLIP_DURATION = 4.0 # length of clip\n",
    "N_CLASSES = 10\n",
    "\n",
    "N_MELS = 128\n",
    "FMIN = 0\n",
    "FMAX = SAMPLE_RATE // 2\n",
    "\n",
    "BATCH_SIZE = 128 # batch size\n",
    "NUM_EPOCHS = 12 # epoch\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 38):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "set_seed(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2993a-2777-48fd-a211-6a4181dcd3bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:40.021402Z",
     "iopub.status.busy": "2025-12-05T05:22:40.021010Z",
     "iopub.status.idle": "2025-12-05T05:22:40.034766Z",
     "shell.execute_reply": "2025-12-05T05:22:40.034093Z",
     "shell.execute_reply.started": "2025-12-05T05:22:40.021382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# augmentation for mel spectrogram (support batch input [B, C, n_mels, T])\n",
    "\n",
    "class SpecAugment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        time_mask_param: int = 20,\n",
    "        freq_mask_param: int = 10,\n",
    "        num_time_masks: int = 2,\n",
    "        num_freq_masks: int = 2,\n",
    "        p: float = 1.0,\n",
    "    ):\n",
    "        self.time_mask_param = time_mask_param\n",
    "        self.freq_mask_param = freq_mask_param\n",
    "        self.num_time_masks = num_time_masks\n",
    "        self.num_freq_masks = num_freq_masks\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, spec: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "            spec: [n_mels, T] or [C, n_mels, T] or [B, C, n_mels, T]\n",
    "            return: same shape\n",
    "        \"\"\"\n",
    "        # Case A: batch input [B, C, n_mels, T]\n",
    "        if spec.dim() == 4:\n",
    "            B, C, n_mels, T = spec.shape\n",
    "            out = []\n",
    "            for b in range(B):\n",
    "                out.append(self._augment_single(spec[b]))   # [C, n_mels, T]\n",
    "            return torch.stack(out, dim=0)\n",
    "\n",
    "        # Case B: single sample [C, n_mels, T]\n",
    "        if spec.dim() == 3:\n",
    "            return self._augment_single(spec)\n",
    "\n",
    "        # Case C: single spectrogram [n_mels, T]\n",
    "        if spec.dim() == 2:\n",
    "            return self._augment_single(spec.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        raise ValueError(f\"Unsupported spec shape: {spec.shape}\")\n",
    "\n",
    "    # do SpecAugment for one sample [C, n_mels, T]\n",
    "    def _augment_single(self, spec: torch.Tensor) -> torch.Tensor:\n",
    "        if random.random() > self.p:\n",
    "            return spec\n",
    "\n",
    "        x = spec.clone()\n",
    "\n",
    "        if x.dim() == 2:\n",
    "            # [n_mels, T] - [1, n_mels, T]\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        C, n_mels, T = x.shape\n",
    "\n",
    "        # freq masks\n",
    "        for _ in range(self.num_freq_masks):\n",
    "            f = random.randint(0, self.freq_mask_param)\n",
    "            if f > 0:\n",
    "                f0 = random.randint(0, max(0, n_mels - f))\n",
    "                x[:, f0:f0 + f, :] = 0.0\n",
    "\n",
    "        # time masks\n",
    "        for _ in range(self.num_time_masks):\n",
    "            t = random.randint(0, self.time_mask_param)\n",
    "            if t > 0:\n",
    "                t0 = random.randint(0, max(0, T - t))\n",
    "                x[:, :, t0:t0 + t] = 0.0\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e84b98c3-1934-4f67-b5ec-a2166af46625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:40.036377Z",
     "iopub.status.busy": "2025-12-05T05:22:40.036138Z",
     "iopub.status.idle": "2025-12-05T05:22:40.053601Z",
     "shell.execute_reply": "2025-12-05T05:22:40.052926Z",
     "shell.execute_reply.started": "2025-12-05T05:22:40.036362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset construct\n",
    "\n",
    "class UrbanSound8KWaveDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        folds: List[int],\n",
    "        sample_rate: int = SAMPLE_RATE,\n",
    "        duration: float = CLIP_DURATION,\n",
    "        waveform_augment: WaveformAugment = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.folds = folds if isinstance(folds, list) else [folds]\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.n_samples = int(sample_rate * duration)\n",
    "        self.waveform_augment = waveform_augment\n",
    "\n",
    "        meta_path = os.path.join(data_dir, \"metadata\", \"UrbanSound8K.csv\")\n",
    "        df = pd.read_csv(meta_path)\n",
    "        self.df = df[df[\"fold\"].isin(self.folds)].reset_index(drop=True)\n",
    "        self.labels = self.df[\"classID\"].astype(int).to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _load_waveform(self, index: int) -> torch.Tensor:\n",
    "        row = self.df.iloc[index]\n",
    "        fold = row[\"fold\"]\n",
    "        filename = row[\"slice_file_name\"]\n",
    "        file_path = os.path.join(self.data_dir, \"audio\", f\"fold{fold}\", filename)\n",
    "\n",
    "        # resample\n",
    "        wav, sr = librosa.load(file_path, sr=self.sample_rate, mono=True)\n",
    "\n",
    "        # pad / truncate to 4 seconds\n",
    "        if len(wav) < self.n_samples:\n",
    "            wav = np.pad(wav, (0, self.n_samples - len(wav)), mode=\"constant\")\n",
    "        elif len(wav) > self.n_samples:\n",
    "            wav = wav[: self.n_samples]\n",
    "\n",
    "        # normalization\n",
    "        if np.std(wav) > 1e-6:\n",
    "            wav = (wav - wav.mean()) / wav.std()\n",
    "\n",
    "        wav = wav.astype(np.float32)\n",
    "        return torch.from_numpy(wav).unsqueeze(0)  # [1, T]\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        label = int(self.labels[index])\n",
    "        wav = self._load_waveform(index)\n",
    "\n",
    "        # data augmentation (for train set)\n",
    "        if self.waveform_augment is not None:\n",
    "            wav = self.waveform_augment(wav)\n",
    "\n",
    "        return wav, torch.tensor(label, dtype=torch.long) # return waveform [1, T] and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97062f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:40.054575Z",
     "iopub.status.busy": "2025-12-05T05:22:40.054373Z",
     "iopub.status.idle": "2025-12-05T05:22:40.069608Z",
     "shell.execute_reply": "2025-12-05T05:22:40.068939Z",
     "shell.execute_reply.started": "2025-12-05T05:22:40.054524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pretrained VGG-13-BN model (pretrained on imagenet1k)\n",
    "\n",
    "def create_pretrained_vgg13(num_classes: int = N_CLASSES) -> nn.Module:\n",
    "    try:\n",
    "        vgg = models.vgg13_bn(weights=models.VGG13_BN_Weights.IMAGENET1K_V1)\n",
    "    except AttributeError:\n",
    "        vgg = models.vgg13_bn(pretrained=True)\n",
    "\n",
    "    # change the last classifier to 10 classes\n",
    "    in_features = vgg.classifier[-1].in_features\n",
    "    vgg.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a348264-fb86-4f19-92ce-a7a4d1254c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:40.070574Z",
     "iopub.status.busy": "2025-12-05T05:22:40.070372Z",
     "iopub.status.idle": "2025-12-05T05:22:40.248285Z",
     "shell.execute_reply": "2025-12-05T05:22:40.247686Z",
     "shell.execute_reply.started": "2025-12-05T05:22:40.070552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# mel transformation (change waveform to mel spectrogram)\n",
    "\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=N_MELS,\n",
    "    f_min=FMIN,\n",
    "    f_max=FMAX,\n",
    "    power=2.0,\n",
    ").to(DEVICE)\n",
    "\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB().to(DEVICE)\n",
    "\n",
    "\n",
    "def waveform_batch_to_mel(x_wave: torch.Tensor) -> torch.Tensor:\n",
    "    x_in = x_wave.squeeze(1)   # [B, T]\n",
    "\n",
    "    # generate mel\n",
    "    mel = mel_transform(x_in)\n",
    "    mel_db = db_transform(mel)\n",
    "\n",
    "    # normalization\n",
    "    mean = mel_db.mean(dim=(1, 2), keepdim=True)\n",
    "    std = mel_db.std(dim=(1, 2), keepdim=True)\n",
    "    mel_db = (mel_db - mean) / (std + 1e-6)\n",
    "\n",
    "    # add dimension for channel [B, 1, n_mels, frames]\n",
    "    mel_db = mel_db.unsqueeze(1)\n",
    "\n",
    "    # augmentation for mel spectrogram\n",
    "    aug = SpecAugment()\n",
    "    mel_db = aug(mel_db)\n",
    "\n",
    "    # copy to 3 channels [B, 3, n_mels, frames]\n",
    "    mel_db = mel_db.repeat(1, 3, 1, 1)\n",
    "\n",
    "    return mel_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb95faf4-eae9-4ba7-84f3-10320906af01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:40.249268Z",
     "iopub.status.busy": "2025-12-05T05:22:40.249022Z",
     "iopub.status.idle": "2025-12-05T05:22:40.256388Z",
     "shell.execute_reply": "2025-12-05T05:22:40.255699Z",
     "shell.execute_reply.started": "2025-12-05T05:22:40.249249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3-stage Fine-tuning\n",
    "\n",
    "def set_trainable_stage(model: nn.Module, stage: int):\n",
    "    \"\"\"\n",
    "    stage 1: only train classifier\n",
    "    stage 2: train the final conv block and classifier\n",
    "    stage 3: train the whole model\n",
    "    \"\"\"\n",
    "    # freeze all\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    if stage == 1:\n",
    "        # unfreeze classifier\n",
    "        for p in model.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    elif stage == 2:\n",
    "        # unfreeze classifier + last conv block\n",
    "        for p in model.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        features = list(model.features.children())\n",
    "        for layer in features[-6:]:\n",
    "            for p in layer.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "    elif stage == 3:\n",
    "        # freeze all\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown stage: {stage}\")\n",
    "\n",
    "\n",
    "def create_optimizer_for_stage(model: nn.Module, stage: int): # construct optimizer\n",
    "    if stage == 1:\n",
    "        lr = 1e-5\n",
    "    elif stage == 2:\n",
    "        lr = 5e-6\n",
    "    elif stage == 3:\n",
    "        lr = 1e-6\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown stage: {stage}\")\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, weight_decay=1e-4) # Adam, L2 regularization\n",
    "    return optimizer, lr\n",
    "\n",
    "def get_stage_for_epoch(epoch: int):\n",
    "    \"\"\"\n",
    "    1-6  : stage 1\n",
    "    11-12 : stage 2\n",
    "    13-20: stage 3\n",
    "    \"\"\"\n",
    "    if epoch <= 6:\n",
    "        return 1\n",
    "    elif epoch <= 12:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5904679-2147-4b88-9d13-dd3a6c6c55b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:40.257351Z",
     "iopub.status.busy": "2025-12-05T05:22:40.257092Z",
     "iopub.status.idle": "2025-12-05T05:22:40.272718Z",
     "shell.execute_reply": "2025-12-05T05:22:40.271996Z",
     "shell.execute_reply.started": "2025-12-05T05:22:40.257332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Functions for train, validate and plot\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device): # train one epoch\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x_wave, y in loader:\n",
    "        x_wave = x_wave.to(device) # [B, 1, T]\n",
    "        y = y.to(device)\n",
    "\n",
    "        # change waveform to mel\n",
    "        x = waveform_batch_to_mel(x_wave) # [B, 1, n_mels, frames]\n",
    "\n",
    "        optimizer.zero_grad() # zero gradient\n",
    "        logits = model(x) # forward\n",
    "        loss = criterion(logits, y) # loss\n",
    "        loss.backward() # backward\n",
    "        optimizer.step() # update\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad() # evaluate\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x_wave, y in loader:\n",
    "        x_wave = x_wave.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x = waveform_batch_to_mel(x_wave)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def plot_learning_curve(history, fold_id: int, save_dir: str = MODEL_DIR): # plot\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"e - Fold {fold_id} - Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"e - Fold {fold_id} - Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, f\"vgg13_e_fold{fold_id}_curve.png\")\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved learning curve to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4f59c6-5a50-4466-b252-ed49aa79fbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T05:22:40.273631Z",
     "iopub.status.busy": "2025-12-05T05:22:40.273387Z",
     "iopub.status.idle": "2025-12-05T09:04:40.597059Z",
     "shell.execute_reply": "2025-12-05T09:04:40.596174Z",
     "shell.execute_reply.started": "2025-12-05T05:22:40.273597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Fold 1 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Val fold:   10\n",
      "Test fold:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg13_bn-abd245e5.pth\" to /root/.cache/torch/hub/checkpoints/vgg13_bn-abd245e5.pth\n",
      "100%|██████████| 508M/508M [00:02<00:00, 225MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 1] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1983, Train Acc: 0.1951\n",
      "Val   Loss: 1.9629, Val   Acc: 0.3847\n",
      "\n",
      "[Fold 1] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.9101, Train Acc: 0.3362\n",
      "Val   Loss: 1.6095, Val   Acc: 0.5400\n",
      "\n",
      "[Fold 1] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6635, Train Acc: 0.4272\n",
      "Val   Loss: 1.3807, Val   Acc: 0.5699\n",
      "\n",
      "[Fold 1] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.5101, Train Acc: 0.4776\n",
      "Val   Loss: 1.2519, Val   Acc: 0.6153\n",
      "\n",
      "[Fold 1] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4206, Train Acc: 0.5031\n",
      "Val   Loss: 1.1763, Val   Acc: 0.6189\n",
      "\n",
      "[Fold 1] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3700, Train Acc: 0.5199\n",
      "Val   Loss: 1.1214, Val   Acc: 0.6667\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 1] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.3252, Train Acc: 0.5273\n",
      "Val   Loss: 1.0794, Val   Acc: 0.6714\n",
      "\n",
      "[Fold 1] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2759, Train Acc: 0.5471\n",
      "Val   Loss: 1.0960, Val   Acc: 0.6428\n",
      "\n",
      "[Fold 1] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2583, Train Acc: 0.5610\n",
      "Val   Loss: 1.0785, Val   Acc: 0.6476\n",
      "\n",
      "[Fold 1] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2301, Train Acc: 0.5644\n",
      "Val   Loss: 1.0597, Val   Acc: 0.6750\n",
      "\n",
      "[Fold 1] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2081, Train Acc: 0.5685\n",
      "Val   Loss: 0.9955, Val   Acc: 0.6894\n",
      "\n",
      "[Fold 1] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1872, Train Acc: 0.5799\n",
      "Val   Loss: 0.9837, Val   Acc: 0.7001\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold1_curve.png\n",
      "[Fold 1] Test Loss: 1.0213, Test Acc: 0.6564\n",
      "Saved model for fold 1 to: /kaggle/working/model-e/vgg13_e_fold1.pth\n",
      "================================================================================\n",
      "Fold 2 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 3, 4, 5, 6, 7, 8, 9]\n",
      "Val fold:   10\n",
      "Test fold:  2\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 2] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1885, Train Acc: 0.1967\n",
      "Val   Loss: 1.9265, Val   Acc: 0.4301\n",
      "\n",
      "[Fold 2] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8818, Train Acc: 0.3565\n",
      "Val   Loss: 1.5406, Val   Acc: 0.5448\n",
      "\n",
      "[Fold 2] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6334, Train Acc: 0.4289\n",
      "Val   Loss: 1.3495, Val   Acc: 0.5663\n",
      "\n",
      "[Fold 2] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4744, Train Acc: 0.4805\n",
      "Val   Loss: 1.2435, Val   Acc: 0.6010\n",
      "\n",
      "[Fold 2] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3871, Train Acc: 0.5162\n",
      "Val   Loss: 1.1543, Val   Acc: 0.6081\n",
      "\n",
      "[Fold 2] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3209, Train Acc: 0.5372\n",
      "Val   Loss: 1.1017, Val   Acc: 0.6296\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 2] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2766, Train Acc: 0.5457\n",
      "Val   Loss: 1.0731, Val   Acc: 0.6440\n",
      "\n",
      "[Fold 2] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2452, Train Acc: 0.5582\n",
      "Val   Loss: 1.0463, Val   Acc: 0.6535\n",
      "\n",
      "[Fold 2] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2222, Train Acc: 0.5680\n",
      "Val   Loss: 1.0512, Val   Acc: 0.6511\n",
      "\n",
      "[Fold 2] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2025, Train Acc: 0.5776\n",
      "Val   Loss: 0.9906, Val   Acc: 0.6846\n",
      "\n",
      "[Fold 2] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1936, Train Acc: 0.5767\n",
      "Val   Loss: 0.9958, Val   Acc: 0.6846\n",
      "\n",
      "[Fold 2] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1620, Train Acc: 0.5894\n",
      "Val   Loss: 0.9561, Val   Acc: 0.6798\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold2_curve.png\n",
      "[Fold 2] Test Loss: 1.0603, Test Acc: 0.6104\n",
      "Saved model for fold 2 to: /kaggle/working/model-e/vgg13_e_fold2.pth\n",
      "================================================================================\n",
      "Fold 3 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 4, 5, 6, 7, 8, 9]\n",
      "Val fold:   10\n",
      "Test fold:  3\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 3] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1805, Train Acc: 0.2083\n",
      "Val   Loss: 1.9626, Val   Acc: 0.3811\n",
      "\n",
      "[Fold 3] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8726, Train Acc: 0.3578\n",
      "Val   Loss: 1.6019, Val   Acc: 0.5233\n",
      "\n",
      "[Fold 3] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6238, Train Acc: 0.4400\n",
      "Val   Loss: 1.3828, Val   Acc: 0.5305\n",
      "\n",
      "[Fold 3] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4902, Train Acc: 0.4752\n",
      "Val   Loss: 1.2673, Val   Acc: 0.5878\n",
      "\n",
      "[Fold 3] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4056, Train Acc: 0.5076\n",
      "Val   Loss: 1.1677, Val   Acc: 0.6356\n",
      "\n",
      "[Fold 3] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3213, Train Acc: 0.5383\n",
      "Val   Loss: 1.1375, Val   Acc: 0.6189\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 3] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2718, Train Acc: 0.5561\n",
      "Val   Loss: 1.0907, Val   Acc: 0.6523\n",
      "\n",
      "[Fold 3] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2652, Train Acc: 0.5528\n",
      "Val   Loss: 1.0931, Val   Acc: 0.6583\n",
      "\n",
      "[Fold 3] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2425, Train Acc: 0.5607\n",
      "Val   Loss: 1.0522, Val   Acc: 0.6595\n",
      "\n",
      "[Fold 3] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2124, Train Acc: 0.5750\n",
      "Val   Loss: 1.0644, Val   Acc: 0.6583\n",
      "\n",
      "[Fold 3] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1838, Train Acc: 0.5857\n",
      "Val   Loss: 1.0028, Val   Acc: 0.6858\n",
      "\n",
      "[Fold 3] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1661, Train Acc: 0.5834\n",
      "Val   Loss: 0.9978, Val   Acc: 0.6738\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold3_curve.png\n",
      "[Fold 3] Test Loss: 1.1411, Test Acc: 0.5632\n",
      "Saved model for fold 3 to: /kaggle/working/model-e/vgg13_e_fold3.pth\n",
      "================================================================================\n",
      "Fold 4 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 5, 6, 7, 8, 9]\n",
      "Val fold:   10\n",
      "Test fold:  4\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 4] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1926, Train Acc: 0.1904\n",
      "Val   Loss: 1.9661, Val   Acc: 0.3919\n",
      "\n",
      "[Fold 4] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8873, Train Acc: 0.3445\n",
      "Val   Loss: 1.5672, Val   Acc: 0.5269\n",
      "\n",
      "[Fold 4] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6500, Train Acc: 0.4175\n",
      "Val   Loss: 1.3209, Val   Acc: 0.5806\n",
      "\n",
      "[Fold 4] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.5095, Train Acc: 0.4663\n",
      "Val   Loss: 1.2644, Val   Acc: 0.5866\n",
      "\n",
      "[Fold 4] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4131, Train Acc: 0.4966\n",
      "Val   Loss: 1.1666, Val   Acc: 0.6225\n",
      "\n",
      "[Fold 4] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3462, Train Acc: 0.5266\n",
      "Val   Loss: 1.1213, Val   Acc: 0.6440\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 4] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.3000, Train Acc: 0.5347\n",
      "Val   Loss: 1.0563, Val   Acc: 0.6703\n",
      "\n",
      "[Fold 4] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2682, Train Acc: 0.5542\n",
      "Val   Loss: 1.0664, Val   Acc: 0.6535\n",
      "\n",
      "[Fold 4] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2516, Train Acc: 0.5497\n",
      "Val   Loss: 1.0456, Val   Acc: 0.6595\n",
      "\n",
      "[Fold 4] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2291, Train Acc: 0.5658\n",
      "Val   Loss: 1.0368, Val   Acc: 0.6667\n",
      "\n",
      "[Fold 4] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2008, Train Acc: 0.5738\n",
      "Val   Loss: 0.9915, Val   Acc: 0.6870\n",
      "\n",
      "[Fold 4] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1690, Train Acc: 0.5871\n",
      "Val   Loss: 0.9986, Val   Acc: 0.6834\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold4_curve.png\n",
      "[Fold 4] Test Loss: 1.0878, Test Acc: 0.6061\n",
      "Saved model for fold 4 to: /kaggle/working/model-e/vgg13_e_fold4.pth\n",
      "================================================================================\n",
      "Fold 5 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 4, 6, 7, 8, 9]\n",
      "Val fold:   10\n",
      "Test fold:  5\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 5] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1747, Train Acc: 0.2120\n",
      "Val   Loss: 1.9437, Val   Acc: 0.3680\n",
      "\n",
      "[Fold 5] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8666, Train Acc: 0.3521\n",
      "Val   Loss: 1.5849, Val   Acc: 0.5197\n",
      "\n",
      "[Fold 5] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6386, Train Acc: 0.4223\n",
      "Val   Loss: 1.3882, Val   Acc: 0.5591\n",
      "\n",
      "[Fold 5] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4796, Train Acc: 0.4765\n",
      "Val   Loss: 1.2523, Val   Acc: 0.5866\n",
      "\n",
      "[Fold 5] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3939, Train Acc: 0.5057\n",
      "Val   Loss: 1.1955, Val   Acc: 0.6201\n",
      "\n",
      "[Fold 5] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3411, Train Acc: 0.5268\n",
      "Val   Loss: 1.1266, Val   Acc: 0.6404\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 5] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2894, Train Acc: 0.5380\n",
      "Val   Loss: 1.1341, Val   Acc: 0.6320\n",
      "\n",
      "[Fold 5] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2526, Train Acc: 0.5564\n",
      "Val   Loss: 1.0778, Val   Acc: 0.6583\n",
      "\n",
      "[Fold 5] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2293, Train Acc: 0.5650\n",
      "Val   Loss: 1.1130, Val   Acc: 0.6153\n",
      "\n",
      "[Fold 5] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2151, Train Acc: 0.5659\n",
      "Val   Loss: 1.0522, Val   Acc: 0.6547\n",
      "\n",
      "[Fold 5] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1974, Train Acc: 0.5725\n",
      "Val   Loss: 1.0612, Val   Acc: 0.6332\n",
      "\n",
      "[Fold 5] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1683, Train Acc: 0.5813\n",
      "Val   Loss: 1.0353, Val   Acc: 0.6703\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold5_curve.png\n",
      "[Fold 5] Test Loss: 1.0979, Test Acc: 0.6207\n",
      "Saved model for fold 5 to: /kaggle/working/model-e/vgg13_e_fold5.pth\n",
      "================================================================================\n",
      "Fold 6 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 4, 5, 7, 8, 9]\n",
      "Val fold:   10\n",
      "Test fold:  6\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 6] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1942, Train Acc: 0.1941\n",
      "Val   Loss: 1.9318, Val   Acc: 0.4146\n",
      "\n",
      "[Fold 6] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8802, Train Acc: 0.3507\n",
      "Val   Loss: 1.5697, Val   Acc: 0.5173\n",
      "\n",
      "[Fold 6] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6413, Train Acc: 0.4311\n",
      "Val   Loss: 1.3593, Val   Acc: 0.5603\n",
      "\n",
      "[Fold 6] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4943, Train Acc: 0.4706\n",
      "Val   Loss: 1.2428, Val   Acc: 0.5711\n",
      "\n",
      "[Fold 6] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3933, Train Acc: 0.5095\n",
      "Val   Loss: 1.1788, Val   Acc: 0.6105\n",
      "\n",
      "[Fold 6] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3296, Train Acc: 0.5366\n",
      "Val   Loss: 1.1044, Val   Acc: 0.6249\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 6] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2758, Train Acc: 0.5495\n",
      "Val   Loss: 1.0637, Val   Acc: 0.6619\n",
      "\n",
      "[Fold 6] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2488, Train Acc: 0.5581\n",
      "Val   Loss: 1.0976, Val   Acc: 0.6272\n",
      "\n",
      "[Fold 6] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2342, Train Acc: 0.5670\n",
      "Val   Loss: 1.0556, Val   Acc: 0.6368\n",
      "\n",
      "[Fold 6] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1961, Train Acc: 0.5718\n",
      "Val   Loss: 1.0566, Val   Acc: 0.6571\n",
      "\n",
      "[Fold 6] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1688, Train Acc: 0.5863\n",
      "Val   Loss: 1.0003, Val   Acc: 0.6667\n",
      "\n",
      "[Fold 6] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1402, Train Acc: 0.5926\n",
      "Val   Loss: 0.9895, Val   Acc: 0.6738\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold6_curve.png\n",
      "[Fold 6] Test Loss: 1.2746, Test Acc: 0.5942\n",
      "Saved model for fold 6 to: /kaggle/working/model-e/vgg13_e_fold6.pth\n",
      "================================================================================\n",
      "Fold 7 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 4, 5, 6, 8, 9]\n",
      "Val fold:   10\n",
      "Test fold:  7\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 7] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1848, Train Acc: 0.2042\n",
      "Val   Loss: 1.9224, Val   Acc: 0.4253\n",
      "\n",
      "[Fold 7] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8642, Train Acc: 0.3636\n",
      "Val   Loss: 1.5339, Val   Acc: 0.5173\n",
      "\n",
      "[Fold 7] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6315, Train Acc: 0.4323\n",
      "Val   Loss: 1.3535, Val   Acc: 0.5568\n",
      "\n",
      "[Fold 7] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4773, Train Acc: 0.4781\n",
      "Val   Loss: 1.2712, Val   Acc: 0.5711\n",
      "\n",
      "[Fold 7] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4002, Train Acc: 0.5101\n",
      "Val   Loss: 1.1668, Val   Acc: 0.6010\n",
      "\n",
      "[Fold 7] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3376, Train Acc: 0.5325\n",
      "Val   Loss: 1.1508, Val   Acc: 0.6201\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 7] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2908, Train Acc: 0.5424\n",
      "Val   Loss: 1.1266, Val   Acc: 0.6308\n",
      "\n",
      "[Fold 7] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2395, Train Acc: 0.5627\n",
      "Val   Loss: 1.0977, Val   Acc: 0.6153\n",
      "\n",
      "[Fold 7] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2250, Train Acc: 0.5689\n",
      "Val   Loss: 1.0843, Val   Acc: 0.6476\n",
      "\n",
      "[Fold 7] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1921, Train Acc: 0.5752\n",
      "Val   Loss: 1.0330, Val   Acc: 0.6559\n",
      "\n",
      "[Fold 7] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1715, Train Acc: 0.5867\n",
      "Val   Loss: 1.0268, Val   Acc: 0.6511\n",
      "\n",
      "[Fold 7] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1617, Train Acc: 0.5881\n",
      "Val   Loss: 1.0083, Val   Acc: 0.6714\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold7_curve.png\n",
      "[Fold 7] Test Loss: 1.2120, Test Acc: 0.5692\n",
      "Saved model for fold 7 to: /kaggle/working/model-e/vgg13_e_fold7.pth\n",
      "================================================================================\n",
      "Fold 8 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 4, 5, 6, 7, 9]\n",
      "Val fold:   10\n",
      "Test fold:  8\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 8] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1921, Train Acc: 0.1985\n",
      "Val   Loss: 1.9470, Val   Acc: 0.4229\n",
      "\n",
      "[Fold 8] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8938, Train Acc: 0.3411\n",
      "Val   Loss: 1.5841, Val   Acc: 0.5054\n",
      "\n",
      "[Fold 8] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6393, Train Acc: 0.4319\n",
      "Val   Loss: 1.3572, Val   Acc: 0.5771\n",
      "\n",
      "[Fold 8] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4982, Train Acc: 0.4747\n",
      "Val   Loss: 1.2411, Val   Acc: 0.6069\n",
      "\n",
      "[Fold 8] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4131, Train Acc: 0.5018\n",
      "Val   Loss: 1.1972, Val   Acc: 0.6081\n",
      "\n",
      "[Fold 8] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3291, Train Acc: 0.5394\n",
      "Val   Loss: 1.0913, Val   Acc: 0.6464\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 8] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2882, Train Acc: 0.5439\n",
      "Val   Loss: 1.0989, Val   Acc: 0.6332\n",
      "\n",
      "[Fold 8] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2453, Train Acc: 0.5573\n",
      "Val   Loss: 1.0897, Val   Acc: 0.6511\n",
      "\n",
      "[Fold 8] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2219, Train Acc: 0.5702\n",
      "Val   Loss: 1.0252, Val   Acc: 0.6631\n",
      "\n",
      "[Fold 8] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2028, Train Acc: 0.5714\n",
      "Val   Loss: 1.0436, Val   Acc: 0.6464\n",
      "\n",
      "[Fold 8] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1981, Train Acc: 0.5778\n",
      "Val   Loss: 1.0335, Val   Acc: 0.6631\n",
      "\n",
      "[Fold 8] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1525, Train Acc: 0.5961\n",
      "Val   Loss: 0.9966, Val   Acc: 0.6726\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold8_curve.png\n",
      "[Fold 8] Test Loss: 1.2580, Test Acc: 0.5856\n",
      "Saved model for fold 8 to: /kaggle/working/model-e/vgg13_e_fold8.pth\n",
      "================================================================================\n",
      "Fold 9 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Val fold:   10\n",
      "Test fold:  9\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 9] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1720, Train Acc: 0.2188\n",
      "Val   Loss: 1.8898, Val   Acc: 0.4194\n",
      "\n",
      "[Fold 9] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8573, Train Acc: 0.3619\n",
      "Val   Loss: 1.5026, Val   Acc: 0.5699\n",
      "\n",
      "[Fold 9] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6248, Train Acc: 0.4337\n",
      "Val   Loss: 1.3299, Val   Acc: 0.5914\n",
      "\n",
      "[Fold 9] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4808, Train Acc: 0.4765\n",
      "Val   Loss: 1.2169, Val   Acc: 0.6153\n",
      "\n",
      "[Fold 9] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3914, Train Acc: 0.5067\n",
      "Val   Loss: 1.1850, Val   Acc: 0.5986\n",
      "\n",
      "[Fold 9] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3404, Train Acc: 0.5206\n",
      "Val   Loss: 1.1538, Val   Acc: 0.6189\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 9] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2842, Train Acc: 0.5465\n",
      "Val   Loss: 1.0680, Val   Acc: 0.6452\n",
      "\n",
      "[Fold 9] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2560, Train Acc: 0.5550\n",
      "Val   Loss: 1.0620, Val   Acc: 0.6428\n",
      "\n",
      "[Fold 9] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2337, Train Acc: 0.5574\n",
      "Val   Loss: 1.0338, Val   Acc: 0.6643\n",
      "\n",
      "[Fold 9] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2152, Train Acc: 0.5728\n",
      "Val   Loss: 1.0546, Val   Acc: 0.6332\n",
      "\n",
      "[Fold 9] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1859, Train Acc: 0.5827\n",
      "Val   Loss: 0.9905, Val   Acc: 0.6607\n",
      "\n",
      "[Fold 9] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1545, Train Acc: 0.5836\n",
      "Val   Loss: 1.0099, Val   Acc: 0.6750\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold9_curve.png\n",
      "[Fold 9] Test Loss: 1.1055, Test Acc: 0.6520\n",
      "Saved model for fold 9 to: /kaggle/working/model-e/vgg13_e_fold9.pth\n",
      "================================================================================\n",
      "Fold 10 as TEST fold\n",
      "================================================================================\n",
      "Train folds: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Val fold:   9\n",
      "Test fold:  10\n",
      "\n",
      "Switch to stage 1 at epoch 1, lr = 1e-05\n",
      "\n",
      "[Fold 10] Epoch 1/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 2.1911, Train Acc: 0.1997\n",
      "Val   Loss: 1.9203, Val   Acc: 0.4473\n",
      "\n",
      "[Fold 10] Epoch 2/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.8851, Train Acc: 0.3551\n",
      "Val   Loss: 1.5708, Val   Acc: 0.5245\n",
      "\n",
      "[Fold 10] Epoch 3/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.6532, Train Acc: 0.4236\n",
      "Val   Loss: 1.3763, Val   Acc: 0.5674\n",
      "\n",
      "[Fold 10] Epoch 4/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.4928, Train Acc: 0.4765\n",
      "Val   Loss: 1.2737, Val   Acc: 0.6103\n",
      "\n",
      "[Fold 10] Epoch 5/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3988, Train Acc: 0.5059\n",
      "Val   Loss: 1.2281, Val   Acc: 0.6005\n",
      "\n",
      "[Fold 10] Epoch 6/12 (Stage 1, lr=1e-05)\n",
      "Train Loss: 1.3312, Train Acc: 0.5221\n",
      "Val   Loss: 1.2125, Val   Acc: 0.6066\n",
      "\n",
      "Switch to stage 2 at epoch 7, lr = 5e-06\n",
      "\n",
      "[Fold 10] Epoch 7/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2823, Train Acc: 0.5384\n",
      "Val   Loss: 1.1517, Val   Acc: 0.6262\n",
      "\n",
      "[Fold 10] Epoch 8/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2512, Train Acc: 0.5570\n",
      "Val   Loss: 1.1345, Val   Acc: 0.6311\n",
      "\n",
      "[Fold 10] Epoch 9/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2462, Train Acc: 0.5488\n",
      "Val   Loss: 1.1491, Val   Acc: 0.6140\n",
      "\n",
      "[Fold 10] Epoch 10/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.2288, Train Acc: 0.5591\n",
      "Val   Loss: 1.1369, Val   Acc: 0.6483\n",
      "\n",
      "[Fold 10] Epoch 11/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1978, Train Acc: 0.5728\n",
      "Val   Loss: 1.1041, Val   Acc: 0.6569\n",
      "\n",
      "[Fold 10] Epoch 12/12 (Stage 2, lr=5e-06)\n",
      "Train Loss: 1.1736, Train Acc: 0.5773\n",
      "Val   Loss: 1.0900, Val   Acc: 0.6471\n",
      "Saved learning curve to: /kaggle/working/model-e/vgg13_e_fold10_curve.png\n",
      "[Fold 10] Test Loss: 1.0109, Test Acc: 0.6655\n",
      "Saved model for fold 10 to: /kaggle/working/model-e/vgg13_e_fold10.pth\n"
     ]
    }
   ],
   "source": [
    "# 10-fold Cross-Validation train\n",
    "\n",
    "all_folds = list(range(1, 11))\n",
    "\n",
    "for test_fold in all_folds:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Fold {test_fold} as TEST fold\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # current fold as test set, remaining 9 folds as train set and val set\n",
    "    trainval_folds = [f for f in all_folds if f != test_fold]\n",
    "\n",
    "    # last fold of remaining 9 set as val set，remaining 8 folds as train set\n",
    "    val_fold = trainval_folds[-1]\n",
    "    train_folds = trainval_folds[:-1]\n",
    "\n",
    "    print(f\"Train folds: {train_folds}\")\n",
    "    print(f\"Val fold:   {val_fold}\")\n",
    "    print(f\"Test fold:  {test_fold}\")\n",
    "\n",
    "    # augmentation\n",
    "    wave_aug = WaveformAugment(sample_rate=SAMPLE_RATE)\n",
    "\n",
    "    train_dataset = UrbanSound8KWaveDataset(\n",
    "        data_dir=DATA_DIR,\n",
    "        folds=train_folds,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        duration=CLIP_DURATION,\n",
    "        waveform_augment=wave_aug # do augmentation\n",
    "    )\n",
    "\n",
    "    val_dataset = UrbanSound8KWaveDataset(\n",
    "        data_dir=DATA_DIR,\n",
    "        folds=[val_fold],\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        duration=CLIP_DURATION,\n",
    "        waveform_augment=None, # don't do augmentation\n",
    "    )\n",
    "\n",
    "    test_dataset = UrbanSound8KWaveDataset(\n",
    "        data_dir=DATA_DIR,\n",
    "        folds=[test_fold],\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        duration=CLIP_DURATION,\n",
    "        waveform_augment=None, # don't do augmentation\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, num_workers=2)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, num_workers=2)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, num_workers=2)\n",
    "\n",
    "    # creat model VGG-13\n",
    "    model = create_pretrained_vgg13(num_classes=N_CLASSES).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_acc\": [],\n",
    "    }\n",
    "\n",
    "    current_stage = None\n",
    "    optimizer = None\n",
    "    current_lr = None\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        stage = get_stage_for_epoch(epoch)\n",
    "        if stage != current_stage:\n",
    "            # reset requires_grad and optimizer when entering new stage\n",
    "            current_stage = stage\n",
    "            set_trainable_stage(model, stage)\n",
    "            optimizer, current_lr = create_optimizer_for_stage(model, stage)\n",
    "            print(f\"\\nSwitch to stage {stage} at epoch {epoch}, lr = {current_lr:g}\")\n",
    "\n",
    "        print(f\"\\n[Fold {test_fold}] Epoch {epoch}/{NUM_EPOCHS} (Stage {current_stage}, lr={current_lr:g})\")\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE) # train one epoch\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, DEVICE) # evaluate on val set\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f}, Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # plot learning curve\n",
    "    plot_learning_curve(history, fold_id=test_fold, save_dir=MODEL_DIR)\n",
    "\n",
    "    # test on test set after finishing training\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, DEVICE)\n",
    "    print(f\"[Fold {test_fold}] Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    # store the model\n",
    "    model_path = os.path.join(MODEL_DIR, f\"vgg13_e_fold{test_fold}.pth\") #  fold i, means that it is used for test for this training\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model for fold {test_fold} to: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8920648,
     "sourceId": 13999533,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
